{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2f67ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_model_summary import summary\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A \n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From path_constants.py\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "dir_path = notebook_dir + '/DummyDatabase'\n",
    "marmot_v1 = dir_path + '/marmot_v1'\n",
    "marmot_extended = dir_path + '/marmot_extended'\n",
    "ORIG_DATA_PATH = f'{marmot_v1}/marmot_dataset_v1.0/data/English'\n",
    "DATA_PATH = 'Marmot_data'\n",
    "PROCESSED_DATA = f'{dir_path}/marmot_processed'\n",
    "PREDICTIONS = f\"{dir_path}/predictions\"\n",
    "TEST_IMAGES = f\"{dir_path}/test_images\"\n",
    "MODELS = f\"{dir_path}/models\"\n",
    "IMAGE_PATH = os.path.join(PROCESSED_DATA, 'image')\n",
    "TABLE_MASK_PATH = os.path.join(PROCESSED_DATA, 'table_mask')\n",
    "COL_MASK_PATH = os.path.join(PROCESSED_DATA, 'col_mask')\n",
    "Marmot_data = f'{dir_path}/{DATA_PATH}'\n",
    "POSITIVE_DATA_LBL = os.path.join(ORIG_DATA_PATH, 'Positive','Labeled')\n",
    "\n",
    "\n",
    "\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From configurations.py\n",
    "\n",
    "SEED = 0\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2\n",
    "WEIGHT_DECAY = 3e-4\n",
    "DATAPATH = f'{PROCESSED_DATA}/processed_data.csv'\n",
    "MODEL_NAME = \"densenet_configuration_4_model_checkpoint.pth.tar\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfcaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From dataset.py\n",
    "\n",
    "class ImageFolder(nn.Module):\n",
    "    def __init__(self, df, transform = None):\n",
    "        super(ImageFolder, self).__init__()\n",
    "        self.df = df\n",
    "        if transform is None:\n",
    "            self.transform = A.Compose([\n",
    "                A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], max_pixel_value = 255,),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, table_mask_path, column_mask_path = self.df.iloc[index, 0], self.df.iloc[index, 1], self.df.iloc[index, 2]\n",
    "        image = np.array(Image.open(image_path))\n",
    "        table_image = torch.FloatTensor(np.array(Image.open(table_mask_path)) / 255.0).reshape(1, 1024, 1024)\n",
    "        column_image = torch.FloatTensor(np.array(Image.open(column_mask_path)) / 255.0).reshape(1, 1024, 1024)\n",
    "        image = self.transform(image = image)['image']\n",
    "        return {\"image\": image, \"table_image\": table_image, \"column_image\": column_image}\n",
    "\n",
    "def get_mean_std(train_data, transform):\n",
    "    dataset = ImageFolder(train_data , transform)\n",
    "    train_loader = DataLoader(dataset, batch_size = 128)\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img_dict in tqdm.tqdm(train_loader):\n",
    "        batch_samples = img_dict[\"image\"].size(0)\n",
    "        images = img_dict[\"image\"].view(batch_samples, img_dict[\"image\"].size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "    mean /= len(train_loader.dataset)\n",
    "    std /= len(train_loader.dataset)\n",
    "    print(mean)\n",
    "    print(std)\n",
    "\n",
    "# Read referencing csv file\n",
    "df = pd.read_csv(f'{PROCESSED_DATA}/processed_data.csv')\n",
    "dataset = ImageFolder(df[df['hasTable'] == 1])\n",
    "img_num = 0\n",
    "for img_dict in dataset:\n",
    "    save_image(img_dict[\"image\"], f'image_{img_num}.png')\n",
    "    save_image(img_dict[\"table_image\"], f'table_image_{img_num}.png')\n",
    "    save_image(img_dict[\"column_image\"], f'column_image_{img_num}.png')\n",
    "    img_num += 1\n",
    "    if img_num == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e96260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From encoder.py\n",
    "\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, pretrained = True, requires_grad = True):\n",
    "        super(VGG19, self).__init__()\n",
    "        _vgg = torchvision.models.vgg19(pretrained = pretrained).features\n",
    "        self.vgg_pool3 = torch.nn.Sequential()\n",
    "        self.vgg_pool4 = torch.nn.Sequential()\n",
    "        self.vgg_pool5 = torch.nn.Sequential()\n",
    "        for x in range(19):\n",
    "            self.vgg_pool3.add_module(str(x), _vgg[x])\n",
    "        for x in range(19, 28):\n",
    "            self.vgg_pool4.add_module(str(x), _vgg[x])\n",
    "        for x in range(28, 37):\n",
    "            self.vgg_pool5.add_module(str(x), _vgg[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x): \n",
    "        pool_3_out = self.vgg_pool3(x)\n",
    "        pool_4_out = self.vgg_pool4(pool_3_out)\n",
    "        pool_5_out = self.vgg_pool5(pool_4_out)\n",
    "        return (pool_3_out, pool_4_out, pool_5_out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, pretrained = True, requires_grad = True):\n",
    "        super(ResNet, self).__init__()\n",
    "        resnet18 = torchvision.models.resnet34(pretrained = True)\n",
    "        self.layer_1 = nn.Sequential(resnet18.conv1, resnet18.bn1, resnet18.relu, resnet18.maxpool, resnet18.layer1)\n",
    "        self.layer_2 = resnet18.layer2\n",
    "        self.layer_3 = resnet18.layer3\n",
    "        self.layer_4 = resnet18.layer4\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.layer_2(self.layer_1(x))\n",
    "        out_2 = self.layer_3(out_1)\n",
    "        out_3 = self.layer_4(out_2)\n",
    "        return out_1, out_2, out_3\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, pretrained = True, requires_grad = True):\n",
    "        super(DenseNet, self).__init__()\n",
    "        denseNet = torchvision.models.densenet121(pretrained = True).features\n",
    "        self.densenet_out_1 = torch.nn.Sequential()\n",
    "        self.densenet_out_2 = torch.nn.Sequential()\n",
    "        self.densenet_out_3 = torch.nn.Sequential()\n",
    "        for x in range(8):\n",
    "            self.densenet_out_1.add_module(str(x), denseNet[x])\n",
    "        for x in range(8,10):\n",
    "            self.densenet_out_2.add_module(str(x), denseNet[x])\n",
    "        self.densenet_out_3.add_module(str(10), denseNet[10])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.densenet_out_1(x)\n",
    "        out_2 = self.densenet_out_2(out_1)\n",
    "        out_3 = self.densenet_out_3(out_2)\n",
    "        return out_1, out_2, out_3\n",
    "\n",
    "class efficientNet_B0(nn.Module):\n",
    "    def __init__(self, pretrained = True, requires_grad = True):\n",
    "        super(efficientNet_B0, self).__init__()\n",
    "        eNet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.eNet_out_1 = torch.nn.Sequential()\n",
    "        self.eNet_out_2 = torch.nn.Sequential()\n",
    "        self.eNet_out_3 = torch.nn.Sequential()\n",
    "        blocks = eNet._blocks\n",
    "        self.eNet_out_1.add_module('_conv_stem', eNet._conv_stem)\n",
    "        self.eNet_out_1.add_module('_bn0', eNet._bn0)\n",
    "        for x in range(14):\n",
    "            self.eNet_out_1.add_module(str(x), blocks[x])\n",
    "        self.eNet_out_2.add_module(str(14), blocks[14])\n",
    "        self.eNet_out_3.add_module(str(15), blocks[15])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.eNet_out_1(x)\n",
    "        out_2 = self.eNet_out_2(out_1)\n",
    "        out_3 = self.eNet_out_3(out_2)\n",
    "        return out_1, out_2, out_3\n",
    "\n",
    "class efficientNet(nn.Module):\n",
    "    def __init__(self, model_type = 'efficientnet-b0',  pretrained = True, requires_grad = True):\n",
    "        super(efficientNet, self).__init__()\n",
    "        eNet = EfficientNet.from_pretrained(model_type)\n",
    "        self.eNet_out_1 = torch.nn.Sequential()\n",
    "        self.eNet_out_2 = torch.nn.Sequential()\n",
    "        self.eNet_out_3 = torch.nn.Sequential()\n",
    "        blocks = eNet._blocks\n",
    "        self.eNet_out_1.add_module('_conv_stem', eNet._conv_stem)\n",
    "        self.eNet_out_1.add_module('_bn0', eNet._bn0)\n",
    "        for x in range(len(blocks)-3):\n",
    "            self.eNet_out_1.add_module(str(x), blocks[x])\n",
    "        self.eNet_out_2.add_module(str(len(blocks)-2), blocks[len(blocks)-2])\n",
    "        self.eNet_out_3.add_module(str(len(blocks)-1), blocks[len(blocks)-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.eNet_out_1(x)\n",
    "        out_2 = self.eNet_out_2(out_1)\n",
    "        out_3 = self.eNet_out_3(out_2)\n",
    "        return out_1, out_2, out_3\n",
    "\n",
    "# model = DenseNet()\n",
    "# x = torch.randn(1, 3, 1024, 1024)\n",
    "# model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f860684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From tablenet_model.py\n",
    "\n",
    "\n",
    "class TableDecoder(nn.Module):\n",
    "    def __init__(self, channels, kernels, strides):\n",
    "        super(TableDecoder, self).__init__()\n",
    "        self.conv_7_table = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = kernels[0], stride = strides[0])\n",
    "        self.upsample_1_table = nn.ConvTranspose2d(in_channels = 256, out_channels=128, kernel_size = kernels[1], stride = strides[1])\n",
    "        self.upsample_2_table = nn.ConvTranspose2d(in_channels = 128 + channels[0], out_channels = 256, kernel_size = kernels[2], stride = strides[2])\n",
    "        self.upsample_3_table = nn.ConvTranspose2d(in_channels = 256 + channels[1], out_channels = 1, kernel_size = kernels[3], stride = strides[3])\n",
    "\n",
    "    def forward(self, x, pool3_out, pool4_out):\n",
    "        x = self.conv_7_table(x)\n",
    "        out = self.upsample_1_table(x)\n",
    "        out = torch.cat((out, pool4_out), dim=1)\n",
    "        out = self.upsample_2_table(out)\n",
    "        out = torch.cat((out, pool3_out), dim=1)\n",
    "        out = self.upsample_3_table(out)\n",
    "        return out\n",
    "\n",
    "class ColumnDecoder(nn.Module):\n",
    "    def __init__(self, channels, kernels, strides):\n",
    "        super(ColumnDecoder, self).__init__()\n",
    "        self.conv_8_column = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256,out_channels = 256,kernel_size = kernels[0], stride = strides[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Conv2d(in_channels = 256,out_channels = 256,kernel_size = kernels[0], stride = strides[0])\n",
    "        )\n",
    "        self.upsample_1_column = nn.ConvTranspose2d(in_channels = 256, out_channels=128, kernel_size = kernels[1], stride = strides[1])\n",
    "        self.upsample_2_column = nn.ConvTranspose2d(in_channels = 128 + channels[0], out_channels = 256, kernel_size = kernels[2], stride = strides[2])\n",
    "        self.upsample_3_column = nn.ConvTranspose2d( in_channels = 256 + channels[1], out_channels = 1, kernel_size = kernels[3], stride = strides[3])\n",
    "\n",
    "    def forward(self, x, pool3_out, pool4_out):\n",
    "        x = self.conv_8_column(x)\n",
    "        out = self.upsample_1_column(x)\n",
    "        out = torch.cat((out, pool4_out), dim=1)\n",
    "        out = self.upsample_2_column(out)\n",
    "        out = torch.cat((out, pool3_out), dim=1)\n",
    "        out = self.upsample_3_column(out)\n",
    "        return out\n",
    "\n",
    "class TableNet(nn.Module):\n",
    "    def __init__(self,encoder = 'vgg', use_pretrained_model = True, basemodel_requires_grad = True):\n",
    "        super(TableNet, self).__init__()\n",
    "        self.kernels = [(1,1), (2,2), (2,2),(8,8)]\n",
    "        self.strides = [(1,1), (2,2), (2,2),(8,8)]\n",
    "        self.in_channels = 512\n",
    "        if encoder == 'vgg':\n",
    "            self.base_model = VGG19(pretrained = use_pretrained_model, requires_grad = basemodel_requires_grad)\n",
    "            self.pool_channels = [512, 256]\n",
    "        elif encoder == 'resnet':\n",
    "            self.base_model = ResNet(pretrained = use_pretrained_model, requires_grad = basemodel_requires_grad)\n",
    "            self.pool_channels = [256, 128]\n",
    "        elif encoder == 'densenet':\n",
    "            self.base_model = DenseNet(pretrained = use_pretrained_model, requires_grad = basemodel_requires_grad)\n",
    "            self.pool_channels = [512, 256]\n",
    "            self.in_channels = 1024\n",
    "            self.kernels = [(1,1), (1,1), (2,2),(16,16)]\n",
    "            self.strides = [(1,1), (1,1), (2,2),(16,16)]\n",
    "        elif 'efficientnet' in encoder:\n",
    "            self.base_model = efficientNet(model_type = encoder, pretrained = use_pretrained_model, requires_grad = basemodel_requires_grad)\n",
    "            if 'b0' in encoder:\n",
    "                self.pool_channels = [192, 192]\n",
    "                self.in_channels = 320\n",
    "            elif 'b1' in encoder:\n",
    "                self.pool_channels = [320, 192]\n",
    "                self.in_channels = 320\n",
    "            elif 'b2' in encoder:\n",
    "                self.pool_channels = [352, 208]\n",
    "                self.in_channels = 352\n",
    "            self.kernels = [(1,1), (1,1), (1,1),(32,32)]\n",
    "            self.strides = [(1,1), (1,1), (1,1),(32,32)]\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = self.in_channels, out_channels = 256, kernel_size=(1,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size=(1,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.8)\n",
    "        )\n",
    "        self.table_decoder = TableDecoder(self.pool_channels, self.kernels, self.strides)\n",
    "        self.column_decoder = ColumnDecoder(self.pool_channels, self.kernels, self.strides)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pool3_out, pool4_out, pool5_out = self.base_model(x)\n",
    "        conv_out = self.conv6(pool5_out)\n",
    "        table_out = self.table_decoder(conv_out, pool3_out, pool4_out)\n",
    "        column_out = self.column_decoder(conv_out, pool3_out, pool4_out)\n",
    "        return table_out, column_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From model_loss.py\n",
    "\n",
    "class TableNetLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TableNetLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, table_prediction, table_target, column_prediction = None, column_target = None,):\n",
    "        table_loss = self.bce(table_prediction, table_target)\n",
    "        column_loss = self.bce(column_prediction, column_target)\n",
    "        return table_loss, column_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From general_utilities.py\n",
    "\n",
    "TRANSFORM = A.Compose([\n",
    "    A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], max_pixel_value = 255,),\n",
    "    ToTensorV2()\n",
    "])\n",
    "# Apply the SEED\n",
    "def seed_all(SEED_VALUE = SEED):\n",
    "    random.seed(SEED_VALUE)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "    torch.cuda.manual_seed(SEED_VALUE)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def get_data_loaders(data_path = DATAPATH):\n",
    "    df = pd.read_csv(data_path)\n",
    "    train_data, test_data  = train_test_split(df, test_size = 0.2, random_state = SEED, stratify = df.hasTable)\n",
    "    train_dataset = ImageFolder(train_data, transform = None)\n",
    "    test_dataset = ImageFolder(test_data, transform = None)\n",
    "    train_loader =  DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "    test_loader =  DataLoader(test_dataset, batch_size = 8, shuffle = False, num_workers = 4, pin_memory = True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Save Checkpoint\n",
    "def save_checkpoint(state, filename = f\"{PROCESSED_DATA}/model_checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "    print(\"Checkpoint Saved at: \", filename)\n",
    "\n",
    "# Load the checkpoint we saved\n",
    "def load_checkpoint(checkpoint, model, optimizer = None):\n",
    "    print(\"Loading checkpoint...\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    tr_metrics = checkpoint['train_metrics']\n",
    "    te_metrics = checkpoint['test_metrics']\n",
    "    return last_epoch, tr_metrics, te_metrics\n",
    "\n",
    "def write_summary(writer, tr_metrics, te_metrics, epoch):\n",
    "    writer.add_scalar(\"Table Loss/Train\", tr_metrics['table_loss'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Loss/Test\", te_metrics['table_loss'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Acc/Train\", tr_metrics['table_acc'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Acc/Test\", te_metrics['table_acc'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table F1/Train\", tr_metrics['table_f1'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table F1/Test\", te_metrics['table_f1'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Precision/Train\", tr_metrics['table_precision'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Precision/Test\", te_metrics['table_precision'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Recall/Train\", tr_metrics['table_recall'], global_step = epoch)\n",
    "    writer.add_scalar(\"Table Recall/Test\", te_metrics['table_recall'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Loss/Train\", tr_metrics['column_loss'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Loss/Test\", te_metrics['column_loss'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Acc/Train\", tr_metrics['col_acc'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Acc/Test\", te_metrics['col_acc'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column F1/Train\", tr_metrics['col_f1'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column F1/Test\", te_metrics['col_f1'], global_step = epoch)    \n",
    "    writer.add_scalar(\"Column Precision/Train\", tr_metrics['col_precision'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Precision/Test\", te_metrics['col_precision'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Recall/Train\", tr_metrics['col_recall'], global_step = epoch)\n",
    "    writer.add_scalar(\"Column Recall/Test\", te_metrics['col_recall'], global_step = epoch)\n",
    "\n",
    "def display_metrics(epoch, tr_metrics, te_metrics):\n",
    "    print(f\"Epoch: {epoch} \\n\\\n",
    "        Table Loss -- Train: {tr_metrics['table_loss']:.3f} Test: {te_metrics['table_loss']:.3f}\\n\\\n",
    "        Table Acc -- Train: {tr_metrics['table_acc']:.3f} Test: {te_metrics['table_acc']:.3f}\\n\\\n",
    "        Table F1 -- Train: {tr_metrics['table_f1']:.3f} Test: {te_metrics['table_f1']:.3f}\\n\\\n",
    "        Table Precision -- Train: {tr_metrics['table_precision']:.3f} Test: {te_metrics['table_precision']:.3f}\\n\\\n",
    "        Table Recall -- Train: {tr_metrics['table_recall']:.3f} Test: {te_metrics['table_recall']:.3f}\\n\\\n",
    "        \\n\\\n",
    "        Col Loss -- Train: {tr_metrics['column_loss']:.3f} Test: {te_metrics['column_loss']:.3f}\\n\\\n",
    "        Col Acc -- Train: {tr_metrics['col_acc']:.3f} Test: {te_metrics['col_acc']:.3f}\\n\\\n",
    "        Col F1 -- Train: {tr_metrics['col_f1']:.3f} Test: {te_metrics['col_f1']:.3f}\\n\\\n",
    "        Col Precision -- Train: {tr_metrics['col_precision']:.3f} Test: {te_metrics['col_precision']:.3f}\\n\\\n",
    "        Col Recall -- Train: {tr_metrics['col_recall']:.3f} Test: {te_metrics['col_recall']:.3f}\\n\"\n",
    "    )\n",
    "\n",
    "def compute_metrics(ground_truth, prediction, threshold = 0.5):\n",
    "    # Ref: https://stackoverflow.com/a/56649983\n",
    "    ground_truth = ground_truth.int()\n",
    "    prediction = (torch.sigmoid(prediction) > threshold).int()\n",
    "    TP = torch.sum(prediction[ground_truth == 1] == 1)\n",
    "    TN = torch.sum(prediction[ground_truth == 0] == 0)\n",
    "    FP = torch.sum(prediction[ground_truth == 1] == 0)\n",
    "    FN = torch.sum(prediction[ground_truth == 0] == 1)\n",
    "    acc = (TP + TN) / (TP + TN + FP+ FN)\n",
    "    precision = TP / (FP + TP + 1e-4)\n",
    "    recall = TP / (FN + TP + 1e-4)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-4)\n",
    "    metrics = {\n",
    "        'acc': acc.item(),\n",
    "        'f1': f1.item(),\n",
    "        'precision':precision.item(),\n",
    "        'recall': recall.item()\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def display(image, table, column, title = 'Original'):\n",
    "    f, ax  = plt.subplots(1, 3, figsize = (15, 8))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(f'{title} Image')\n",
    "    ax[1].imshow(table)\n",
    "    ax[1].set_title(f'{title} Table Mask')\n",
    "    ax[2].imshow(column)\n",
    "    ax[2].set_title(f'{title} Column Mask')\n",
    "    plt.show()\n",
    "\n",
    "def display_prediction(image, table = None, table_image = None, no_: bool = False):\n",
    "  if no_:\n",
    "    f1, ax  = plt.subplots(1, 1, figsize = (7, 5))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title('Original Image')\n",
    "    f1.suptitle('No Tables Detected')\n",
    "  else:\n",
    "    f2, ax  = plt.subplots(1, 3, figsize = (15, 8))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(table)\n",
    "    ax[1].set_title('Image with Predicted Table')\n",
    "    ax[2].imshow(table_image)\n",
    "    ax[2].set_title('Predicted Table Example')\n",
    "  plt.show()\n",
    "\n",
    "def get_TableMasks(test_image, model, transform = TRANSFORM, device = DEVICE):\n",
    "    image = transform(image = test_image)[\"image\"]\n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device).unsqueeze(0)\n",
    "        # With torch.cuda.amp.autocast():\n",
    "        table_out, column_out  = model(image)\n",
    "        table_out = torch.sigmoid(table_out)\n",
    "        column_out = torch.sigmoid(column_out)\n",
    "    # Remove gradients\n",
    "    table_out = (table_out.cpu().detach().numpy().squeeze(0).transpose(1, 2, 0) > 0.5).astype(int)\n",
    "    column_out = (column_out.cpu().detach().numpy().squeeze(0).transpose(1, 2, 0) > 0.5).astype(int)\n",
    "    # Return masks\n",
    "    return table_out, column_out\n",
    "\n",
    "def fixMasks(image, table_mask, column_mask):\n",
    "    \"\"\" Fix Table Bounding Box to get better OCR predictions \"\"\"\n",
    "    table_mask = table_mask.reshape(1024, 1024).astype(np.uint8)\n",
    "    column_mask = column_mask.reshape(1024, 1024).astype(np.uint8)\n",
    "    # Get contours of the mask to get number of tables\n",
    "    contours, table_heirarchy = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    table_contours = []\n",
    "    # Ref: https://www.pyimagesearch.com/2015/02/09/removing-contours-image-using-python-opencv/\n",
    "    # Remove bad contours\n",
    "    for c in contours:\n",
    "        # if the contour is bad, draw it on the mask\n",
    "        if cv2.contourArea(c) > 2000:\n",
    "            table_contours.append(c)\n",
    "    if len(table_contours) == 0:\n",
    "        return None\n",
    "    # Ref : https://docs.opencv.org/4.5.2/da/d0c/tutorial_bounding_rects_circles.html\n",
    "    # Get bounding box for the contour\n",
    "    table_bound_rect = [None] * len(table_contours)\n",
    "    for i, c in enumerate(table_contours):\n",
    "        polygon = cv2.approxPolyDP(c, 3, True)\n",
    "        table_bound_rect[i] = cv2.boundingRect(polygon)\n",
    "    # Table bounding Box\n",
    "    table_bound_rect.sort()\n",
    "    column_bound_rects = []\n",
    "    for x, y, w, h in table_bound_rect:\n",
    "        column_mask_crop = column_mask[y : y + h, x : x + w]\n",
    "        # Get contours of the mask to get number of tables\n",
    "        contours, column_heirarchy = cv2.findContours(column_mask_crop, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # Get bounding box for the contour\n",
    "        bound_rect = [None] * len(contours)\n",
    "        for i, c in enumerate(contours):\n",
    "            polygon = cv2.approxPolyDP(c, 3, True)\n",
    "            bound_rect[i] = cv2.boundingRect(polygon)\n",
    "            # Adjusting columns as per table coordinates\n",
    "            bound_rect[i] = (bound_rect[i][0] + x, bound_rect[i][1] + y, bound_rect[i][2], bound_rect[i][3])\n",
    "        column_bound_rects.append(bound_rect)\n",
    "    image = image[...,0].reshape(1024, 1024).astype(np.uint8)\n",
    "    # Draw bounding boxes\n",
    "    color = (0, 255, 0)\n",
    "    thickness = 4\n",
    "    for x, y, w, h in table_bound_rect:\n",
    "        image = cv2.rectangle(image, (x, y),(x + w, y + h), color, thickness)\n",
    "    return image, table_bound_rect, column_bound_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def train_on_epoch(data_loader, model, optimizer, loss, scaler, threshold = 0.5):\n",
    "    combined_loss = []\n",
    "    table_loss, table_acc, table_precision, table_recall, table_f1 = [], [], [], [], []\n",
    "    column_loss, column_acc, column_precision, column_recall, column_f1 = [], [], [], [], []\n",
    "    loop = tqdm(data_loader, leave = True)\n",
    "    for batch_i, image_dict in enumerate(loop):\n",
    "        image            = image_dict[\"image\"].to(DEVICE)\n",
    "        table_image      = image_dict[\"table_image\"].to(DEVICE)\n",
    "        column_image     = image_dict[\"column_image\"].to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            table_out, column_out = model(image)\n",
    "            i_table_loss, i_column_loss = loss(table_out, table_image, column_out, column_image)\n",
    "        table_loss.append(i_table_loss.item())\n",
    "        column_loss.append(i_column_loss.item())\n",
    "        combined_loss.append((i_table_loss + i_column_loss).item())\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(i_table_loss + i_column_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        mean_loss = sum(combined_loss) / len(combined_loss)\n",
    "        loop.set_postfix(loss = mean_loss)\n",
    "        cal_metrics_table = compute_metrics(table_image, table_out, threshold)\n",
    "        cal_metrics_col = compute_metrics(column_image, column_out, threshold)\n",
    "        table_f1.append(cal_metrics_table['f1'])\n",
    "        table_precision.append(cal_metrics_table['precision'])\n",
    "        table_acc.append(cal_metrics_table['acc'])\n",
    "        table_recall.append(cal_metrics_table['recall'])\n",
    "        column_f1.append(cal_metrics_col['f1'])\n",
    "        column_acc.append(cal_metrics_col['acc'])\n",
    "        column_precision.append(cal_metrics_col['precision'])\n",
    "        column_recall.append(cal_metrics_col['recall'])\n",
    "        metrics = {\n",
    "          'combined_loss': np.mean(combined_loss),\n",
    "          'table_loss': np.mean(table_loss),\n",
    "          'column_loss': np.mean(column_loss),\n",
    "          'table_acc': np.mean(table_acc),\n",
    "          'col_acc': np.mean(column_acc),\n",
    "          'table_f1': np.mean(table_f1),\n",
    "          'col_f1': np.mean(column_f1),\n",
    "          'table_precision': np.mean(table_precision),\n",
    "          'col_precision': np.mean(column_precision),\n",
    "          'table_recall': np.mean(table_recall),\n",
    "          'col_recall': np.mean(column_recall)\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def test_on_epoch(data_loader, model, loss, threshold = 0.5, device = DEVICE):\n",
    "    combined_loss = []\n",
    "    table_loss, table_acc, table_precision, table_recall, table_f1 = [], [], [], [], []\n",
    "    column_loss, column_acc, column_precision, column_recall, column_f1 = [], [], [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(data_loader, leave = True)\n",
    "        for batch_i, image_dict in enumerate(loop):\n",
    "            image            = image_dict[\"image\"].to(device)\n",
    "            table_image      = image_dict[\"table_image\"].to(device)\n",
    "            column_image     = image_dict[\"column_image\"].to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                table_out, column_out  = model(image)\n",
    "                i_table_loss, i_column_loss = loss(table_out, table_image, column_out, column_image)\n",
    "            table_loss.append(i_table_loss.item())\n",
    "            column_loss.append(i_column_loss.item())\n",
    "            combined_loss.append((i_table_loss + i_column_loss).item())\n",
    "            mean_loss = sum(combined_loss) / len(combined_loss)\n",
    "            loop.set_postfix(loss=mean_loss)\n",
    "            cal_metrics_table = compute_metrics(table_image, table_out, threshold)\n",
    "            cal_metrics_col = compute_metrics(column_image, column_out, threshold)\n",
    "            table_f1.append(cal_metrics_table['f1'])\n",
    "            table_precision.append(cal_metrics_table['precision'])\n",
    "            table_acc.append(cal_metrics_table['acc'])\n",
    "            table_recall.append(cal_metrics_table['recall'])\n",
    "            column_f1.append(cal_metrics_col['f1'])\n",
    "            column_acc.append(cal_metrics_col['acc'])\n",
    "            column_precision.append(cal_metrics_col['precision'])\n",
    "            column_recall.append(cal_metrics_col['recall'])\n",
    "    metrics = {\n",
    "        'combined_loss': np.mean(combined_loss),\n",
    "        'table_loss': np.mean(table_loss),\n",
    "        'column_loss': np.mean(column_loss),\n",
    "        'table_acc': np.mean(table_acc),\n",
    "        'col_acc': np.mean(column_acc),\n",
    "        'table_f1': np.mean(table_f1),\n",
    "        'col_f1': np.mean(column_f1),\n",
    "        'table_precision': np.mean(table_precision),\n",
    "        'col_precision': np.mean(column_precision),\n",
    "        'table_recall': np.mean(table_recall),\n",
    "        'col_recall': np.mean(column_recall)\n",
    "    }\n",
    "    model.train()\n",
    "    return metrics\n",
    "\n",
    "seed_all(SEED_VALUE = SEED)\n",
    "checkpoint_name = f'{PROCESSED_DATA}/{MODEL_NAME}'\n",
    "model = TableNet(encoder = 'densenet', use_pretrained_model = True, basemodel_requires_grad = True)\n",
    "\n",
    "print(\"Model Architecture and Trainable Paramerters\")\n",
    "print(\"=\"*50)\n",
    "print(summary(model, torch.zeros((1, 3, 1024, 1024)), show_input = False, show_hierarchical = True))\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "loss = TableNetLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "train_loader, test_loader = get_data_loaders(data_path = DATAPATH)\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.exists(checkpoint_name):\n",
    "    last_epoch, train_metrics, test_metrics = load_checkpoint(torch.load(checkpoint_name), model)\n",
    "    last_table_f1 = test_metrics['table_f1']\n",
    "    last_column_f1 = test_metrics['col_f1']\n",
    "    print(\"Loading Checkpoint...\")\n",
    "    display_metrics(last_epoch, train_metrics, test_metrics)\n",
    "    print()\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    last_table_f1 = 0.\n",
    "    last_column_f1 = 0.\n",
    "\n",
    "# Train Network\n",
    "print(\"Training Model\\n\")\n",
    "writer = SummaryWriter(f\"{PROCESSED_DATA}/runs/TableNet/densenet/configuration_4_batch_{BATCH_SIZE}_learningrate_{LEARNING_RATE}_encoder_train\")\n",
    "# For early stopping\n",
    "i = 0\n",
    "\n",
    "for epoch in range(last_epoch + 1, EPOCHS):\n",
    "    print(\"=\"*30)\n",
    "    start = time.time()\n",
    "    train_metrics = train_on_epoch(train_loader, model, optimizer, loss, scaler, threshold = 0.5)\n",
    "    test_metrics = test_on_epoch(test_loader, model, loss, threshold = 0.5)\n",
    "    write_summary(writer, train_metrics, test_metrics, epoch)\n",
    "    end = time.time()\n",
    "    display_metrics(epoch, train_metrics, test_metrics)\n",
    "    if last_table_f1 < test_metrics['table_f1'] or last_column_f1 < test_metrics['col_f1']:\n",
    "        last_table_f1 = test_metrics['table_f1']\n",
    "        last_column_f1 = test_metrics['col_f1']\n",
    "        checkpoint = {\n",
    "            'epoch': epoch, \n",
    "            'state_dict': model.state_dict(), \n",
    "            'optimizer': optimizer.state_dict(), \n",
    "            'train_metrics': train_metrics, \n",
    "            'test_metrics': test_metrics\n",
    "        }\n",
    "        save_checkpoint(checkpoint, checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f8c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
