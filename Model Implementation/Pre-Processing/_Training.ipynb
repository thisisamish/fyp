{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6acad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "# Append the parent directory (Model Implementation) to the Python path\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdfaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "from Training.configurations import DATAPATH, DEVICE, EPOCHS, LEARNING_RATE, MODEL_NAME, SEED, WEIGHT_DECAY, BATCH_SIZE\n",
    "from Training.path_constants import PROCESSED_DATA\n",
    "from Training.tablenet_model import TableNet\n",
    "from Training.model_loss import TableNetLoss\n",
    "from Training.general_utilities import compute_metrics, seed_all, get_data_loaders, load_checkpoint, display_metrics, write_summary, save_checkpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def train_on_epoch(data_loader, model, optimizer, loss, scaler, threshold = 0.5):\n",
    "    combined_loss = []\n",
    "    table_loss, table_acc, table_precision, table_recall, table_f1 = [], [], [], [], []\n",
    "    column_loss, column_acc, column_precision, column_recall, column_f1 = [], [], [], [], []\n",
    "    loop = tqdm(data_loader, leave = True)\n",
    "    for batch_i, image_dict in enumerate(loop):\n",
    "        image            = image_dict[\"image\"].to(DEVICE)\n",
    "        table_image      = image_dict[\"table_image\"].to(DEVICE)\n",
    "        column_image     = image_dict[\"column_image\"].to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            table_out, column_out = model(image)\n",
    "            i_table_loss, i_column_loss = loss(table_out, table_image, column_out, column_image)\n",
    "        table_loss.append(i_table_loss.item())\n",
    "        column_loss.append(i_column_loss.item())\n",
    "        combined_loss.append((i_table_loss + i_column_loss).item())\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(i_table_loss + i_column_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        mean_loss = sum(combined_loss) / len(combined_loss)\n",
    "        loop.set_postfix(loss = mean_loss)\n",
    "        cal_metrics_table = compute_metrics(table_image, table_out, threshold)\n",
    "        cal_metrics_col = compute_metrics(column_image, column_out, threshold)\n",
    "        table_f1.append(cal_metrics_table['f1'])\n",
    "        table_precision.append(cal_metrics_table['precision'])\n",
    "        table_acc.append(cal_metrics_table['acc'])\n",
    "        table_recall.append(cal_metrics_table['recall'])\n",
    "        column_f1.append(cal_metrics_col['f1'])\n",
    "        column_acc.append(cal_metrics_col['acc'])\n",
    "        column_precision.append(cal_metrics_col['precision'])\n",
    "        column_recall.append(cal_metrics_col['recall'])\n",
    "        metrics = {\n",
    "          'combined_loss': np.mean(combined_loss),\n",
    "          'table_loss': np.mean(table_loss),\n",
    "          'column_loss': np.mean(column_loss),\n",
    "          'table_acc': np.mean(table_acc),\n",
    "          'col_acc': np.mean(column_acc),\n",
    "          'table_f1': np.mean(table_f1),\n",
    "          'col_f1': np.mean(column_f1),\n",
    "          'table_precision': np.mean(table_precision),\n",
    "          'col_precision': np.mean(column_precision),\n",
    "          'table_recall': np.mean(table_recall),\n",
    "          'col_recall': np.mean(column_recall)\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def test_on_epoch(data_loader, model, loss, threshold = 0.5, device = DEVICE):\n",
    "    combined_loss = []\n",
    "    table_loss, table_acc, table_precision, table_recall, table_f1 = [], [], [], [], []\n",
    "    column_loss, column_acc, column_precision, column_recall, column_f1 = [], [], [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(data_loader, leave = True)\n",
    "        for batch_i, image_dict in enumerate(loop):\n",
    "            image            = image_dict[\"image\"].to(device)\n",
    "            table_image      = image_dict[\"table_image\"].to(device)\n",
    "            column_image     = image_dict[\"column_image\"].to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                table_out, column_out  = model(image)\n",
    "                i_table_loss, i_column_loss = loss(table_out, table_image, column_out, column_image)\n",
    "            table_loss.append(i_table_loss.item())\n",
    "            column_loss.append(i_column_loss.item())\n",
    "            combined_loss.append((i_table_loss + i_column_loss).item())\n",
    "            mean_loss = sum(combined_loss) / len(combined_loss)\n",
    "            loop.set_postfix(loss=mean_loss)\n",
    "            cal_metrics_table = compute_metrics(table_image, table_out, threshold)\n",
    "            cal_metrics_col = compute_metrics(column_image, column_out, threshold)\n",
    "            table_f1.append(cal_metrics_table['f1'])\n",
    "            table_precision.append(cal_metrics_table['precision'])\n",
    "            table_acc.append(cal_metrics_table['acc'])\n",
    "            table_recall.append(cal_metrics_table['recall'])\n",
    "            column_f1.append(cal_metrics_col['f1'])\n",
    "            column_acc.append(cal_metrics_col['acc'])\n",
    "            column_precision.append(cal_metrics_col['precision'])\n",
    "            column_recall.append(cal_metrics_col['recall'])\n",
    "    metrics = {\n",
    "        'combined_loss': np.mean(combined_loss),\n",
    "        'table_loss': np.mean(table_loss),\n",
    "        'column_loss': np.mean(column_loss),\n",
    "        'table_acc': np.mean(table_acc),\n",
    "        'col_acc': np.mean(column_acc),\n",
    "        'table_f1': np.mean(table_f1),\n",
    "        'col_f1': np.mean(column_f1),\n",
    "        'table_precision': np.mean(table_precision),\n",
    "        'col_precision': np.mean(column_precision),\n",
    "        'table_recall': np.mean(table_recall),\n",
    "        'col_recall': np.mean(column_recall)\n",
    "    }\n",
    "    model.train()\n",
    "    return metrics\n",
    "\n",
    "seed_all(SEED_VALUE = SEED)\n",
    "checkpoint_name = f'{PROCESSED_DATA}/{MODEL_NAME}'\n",
    "model = TableNet(encoder = 'densenet', use_pretrained_model = True, basemodel_requires_grad = True)\n",
    "\n",
    "print(\"Model Architecture and Trainable Parameters\")\n",
    "print(\"=\"*50)\n",
    "print(summary(model, torch.zeros((1, 3, 1024, 1024)), show_input = False, show_hierarchical = True))\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "loss = TableNetLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "train_loader, test_loader = get_data_loaders(data_path = DATAPATH)\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.exists(checkpoint_name):\n",
    "    last_epoch, train_metrics, test_metrics = load_checkpoint(torch.load(checkpoint_name), model)\n",
    "    last_table_f1 = test_metrics['table_f1']\n",
    "    last_column_f1 = test_metrics['col_f1']\n",
    "    print(\"Loading Checkpoint...\")\n",
    "    display_metrics(last_epoch, train_metrics, test_metrics)\n",
    "    print()\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    last_table_f1 = 0.\n",
    "    last_column_f1 = 0.\n",
    "\n",
    "# Train Network\n",
    "print(\"Training Model\\n\")\n",
    "writer = SummaryWriter(f\"{PROCESSED_DATA}/runs/TableNet/densenet/configuration_4_batch_{BATCH_SIZE}_learningrate_{LEARNING_RATE}_encoder_train\")\n",
    "# For early stopping\n",
    "i = 0\n",
    "\n",
    "for epoch in range(last_epoch + 1, EPOCHS):\n",
    "    print(\"=\"*30)\n",
    "    start = time.time()\n",
    "    train_metrics = train_on_epoch(train_loader, model, optimizer, loss, scaler, threshold = 0.5)\n",
    "    test_metrics = test_on_epoch(test_loader, model, loss, threshold = 0.5)\n",
    "    write_summary(writer, train_metrics, test_metrics, epoch)\n",
    "    end = time.time()\n",
    "    display_metrics(epoch, train_metrics, test_metrics)\n",
    "    if last_table_f1 < test_metrics['table_f1'] or last_column_f1 < test_metrics['col_f1']:\n",
    "        last_table_f1 = test_metrics['table_f1']\n",
    "        last_column_f1 = test_metrics['col_f1']\n",
    "        checkpoint = {\n",
    "            'epoch': epoch, \n",
    "            'state_dict': model.state_dict(), \n",
    "            'optimizer': optimizer.state_dict(), \n",
    "            'train_metrics': train_metrics, \n",
    "            'test_metrics': test_metrics\n",
    "        }\n",
    "        save_checkpoint(checkpoint, checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb1e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
